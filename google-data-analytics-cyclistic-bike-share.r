{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Google Data Analytics: Capstone Case Study Project\n## Cyclistic Bike-Share Analysis\n\n### Author: Azim Ali\n### 2022-08-02\n\n*This notebook will transcribe the cleaning, manipulation, and analysis conducted for the Cyclistic Bike-Share Analysis*\n*This project is meant to practice and develop skills in various Data Analytic tools. As such, repetitive tasks may be observed in an effort to distinguish how certain programs handle certain tasks differently.*\n\n### Step 1: Call Required Libraries\n\n```\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(skimr)\nlibrary(janitor)\n```\n\n### Step 2: Upload Datasets Into RStudio for Analysis\n***Uploaded data is a 12-month look back from July 1, 2021 to June 30, 2022***\n\n```\ncyclistic_202107 <- read_csv(\"1-Jul-2021-divvy-tripdata.csv\")\ncyclistic_202108 <- read_csv(\"2-Aug-2021-divvy-tripdata.csv\")\ncyclistic_202109 <- read_csv(\"3-Sep-2021-divvy-tripdata.csv\")\ncyclistic_202110 <- read_csv(\"4-Oct-2021-divvy-tripdata.csv\")\ncyclistic_202111 <- read_csv(\"5-Nov-2021-divvy-tripdata.csv\")\ncyclistic_202112 <- read_csv(\"6-Dec-2021-divvy-tripdata.csv\")\ncyclistic_202201 <- read_csv(\"7-Jan-2022-divvy-tripdata.csv\")\ncyclistic_202202 <- read_csv(\"8-Feb-2022-divvy-tripdata.csv\")\ncyclistic_202203 <- read_csv(\"9-Mar-2022-divvy-tripdata.csv\")\ncyclistic_202204 <- read_csv(\"10-Apr-2022-divvy-tripdata.csv\")\ncyclistic_202205 <- read_csv(\"11-May-2022-divvy-tripdata.csv\")\ncyclistic_202206 <- read_csv(\"12-Jun-2022-divvy-tripdata.csv\")\n```\n\n### Step 3: Prepare and Merge Indivdual Datasets Into One\n\n*Compare column names of each dataset to ensure uniformity to avoid issues when datasets are merged.*\n\n```\ncompare_df_cols_same(cyclistic_202107, cyclistic_202108, cyclistic_202109,\n                     cyclistic_202110, cyclistic_202111, cyclistic_202112,\n                     cyclistic_202201, cyclistic_202202, cyclistic_202203,\n                     cyclistic_202204, cyclistic_202205, cyclistic_202206)\n```\n\n*Once column uniformity confirmed across all datasets, merge into individual dataset.*\n\n```\ntrips_ytd <- bind_rows(cyclistic_202107, cyclistic_202108, cyclistic_202109\n                       ,cyclistic_202110, cyclistic_202111, cyclistic_202112\n                       ,cyclistic_202201, cyclistic_202202, cyclistic_202203\n                       ,cyclistic_202204, cyclistic_202205, cyclistic_202206)\n```\n\n*Inspect merged dataset by running summaries to inspect the new dataset.*\n\n*Ensure column names properly translated*\n```\ncolnames(trips_ytd)\n```\n\n*Observe dimensions of merged dataset*\n```\ndim(trips_ytd)\n```\n*Examine column and associated data types.*\n```\nstr(trips_ytd)\n```\n*Review statistical summary of numeric data.*\n```\nsummary(trips_ytd)\n```\n*Determine if there are any unexpected values in member_casual column.*\n```\ntable(trips_ytd$member_casual) - determine if any unexpected values.\n\n```\n\n### Step 4: Add Data for Analysis Purposes\n\n*Add columns for Date, month, day, and year of each record.*\n\n```\ntrips_ytd$date <- as.Date(trips_ytd$started_at)\ntrips_ytd$month <- format(as.Date(trips_ytd$date),\"%m\")\ntrips_ytd$day <- format(as.Date(trips_ytd$date),\"%d\")\ntrips_ytd$year <-format(as.Date(trips_ytd$date), \"%Y\")\ntrips_ytd$day_of_week <- format(as.Date(trips_ytd$date), \"%A\")\n```\n\n*Calculate ride_length in seconds for each record.*\n\n```\ntrips_ytd$ride_length <- difftime(trips_ytd$ended_at, trips_ytd$started_at)\n```\n\n*Set and confirm ride_length as numeric data so it can be used as a calculation input.*\n```\ntrips_ytd$ride_length <- as.numeric(as.character(trips_ytd$ride_length))\nis.numeric(trips_ytd$ride_length)\n```\n\n### Step 5: Clean Dataset\n\n*Data set contains negative values for calculated ride_length as well as unpopulated data for started_at and ended_at columns on certain records.*\n*Negative ride_length does not make sense with data and must be removed. Unpopulated data for start or end locations indicates bikes that are\ntaken out of circulation for maintenance purposes and must also be removed.*\n\n*Create new dataset that removes records with a negative ride_length. A new dataset was created to preserve previous versions incase errors arise.*\n\n```\ntrips_ytd_v2 <- trips_ytd[!(trips_ytd$ride_length < 0),]\n```\n*Create final data set to omit records with N/A values in started_at and ended_at locations. A new dataset created to perserve steps and versions incase errors arise.*\n```\ntrips_ytd_final = na.omit(trips_ytd_v2)\n```\n\n\n### Step 6: Conduct Descriptive Analysis\n\n```\nsummary(trips_ytd_final$ride_length)\naggregate(trips_ytd_final$ride_length ~ trips_ytd_final$member_casual, FUN = mean)\naggregate(trips_ytd_final$ride_length ~ trips_ytd_final$member_casual, FUN = median)\naggregate(trips_ytd_final$ride_length ~ trips_ytd_final$member_casual, FUN = max)\naggregate(trips_ytd_final$ride_length ~ trips_ytd_final$member_casual, FUN = min)\n```\n\n*Order day_of_week column.*\n```\ntrips_ytd_final$day_of_week <- ordered(trips_ytd_final$day_of_week, levels=c(\"Sunday\", \"Monday\", \"Tuesday\",\n                                                                             \"Wednesday\", \"Thursday\", \"Friday\",\n                                                                             \"Saturday\"))\n```\n\n*Run further analysis.*\n```\naggregate(trips_ytd_final$ride_length ~ trips_ytd_final$member_casual + trips_ytd_final$day_of_week, FUN = mean)\n\ntrips_ytd_final %>%\n  mutate(weekday = wday(started_at), label = TRUE) %>%\n  group_by(member_casual, weekday) %>%\n  summarise(number_of_rides = n()\n            ,average_duration = mean(ride_length)) %>%\n  arrange(member_casual, weekday)\n```\n\n### Step 7: Data Visualization\n\n*Data Visualization for number of rides by rider type.*\n```\ntrips_ytd_final %>%\n  mutate(weekday = wday(started_at), label = TRUE) %>%\n  group_by(member_casual, weekday) %>%\n  summarise(number_of_rides = n()\n            ,average_duration = mean(ride_length)) %>%\n  arrange(member_casual, weekday) %>%\n  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +\n  geom_col(position = \"dodge\")\n```\n\n*Data Visualization for average duration by rider type.*\n```\ntrips_ytd_final %>%\n  mutate(weekday = wday(started_at), label = TRUE) %>%\n  group_by(member_casual, weekday) %>%\n  summarise(number_of_rides = n()\n            ,average_duration = mean(ride_length)) %>%\n  arrange(member_casual, weekday) %>%\n  ggplot(aes(x = weekday, y = average_duration, fill = member_casual)) +\n  geom_col(position = \"dodge\")\n```\n\n\n### Step 8: Exporting Data\n\n*At this stage, I planned to export data that was processed in RStudio for use and practice in Tableau. Upon export, the resulting file size was too big for upload in Tableau Public. Due to this, a new dataset was created to remove columns that would not be used in analysis. Starting and ending latitude and longitude columns were removed in an effort to reduce resulting file size.*\n\n```\ntrips_ytd_final_v2 <- trips_ytd_final %>%\n  select(-c(start_lat, end_lat, start_lng, end_lng))\n```\n\n*Once removed, final dataset was exported to a CSV file for further analysis. Dataset is attached for reference.*\n```\nwrite.csv(trips_ytd_final_v2, \"trips_ytd_final_v1.csv\")\n```","metadata":{}}]}